[
  {
    "objectID": "Homework9.html",
    "href": "Homework9.html",
    "title": "Homework 9",
    "section": "",
    "text": "Note, we start this homework by copying the quarto document from Homework 8 into this new quarto document for Homework 9. There is a heading below which specifies where the new material unique to Homework 9 begins."
  },
  {
    "objectID": "Homework9.html#loading-packages",
    "href": "Homework9.html#loading-packages",
    "title": "Homework 9",
    "section": "Loading Packages",
    "text": "Loading Packages\nFirst we load all packages which will be needed for this assignment.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ recipes      1.3.1      ✔ yardstick    1.3.2 \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(matrixStats)\n\n\nAttaching package: 'matrixStats'\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\nlibrary(ggcorrplot)\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.5.2\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-10\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.5.2\n\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.5.2\n\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune"
  },
  {
    "objectID": "Homework9.html#reading-data",
    "href": "Homework9.html#reading-data",
    "title": "Homework 9",
    "section": "Reading Data",
    "text": "Reading Data\nNext we read in the data.\n\nrentals &lt;- read_csv('https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv', locale=locale(encoding=\"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Homework9.html#eda",
    "href": "Homework9.html#eda",
    "title": "Homework 9",
    "section": "EDA",
    "text": "EDA\nNow we perform some exploratory data analysis.\nStep 1. In this step, we check our imported tibble for missing data.\n\ncolSums(is.na(rentals))\n\n                     Date         Rented Bike Count                      Hour \n                        0                         0                         0 \n          Temperature(°C)               Humidity(%)          Wind speed (m/s) \n                        0                         0                         0 \n         Visibility (10m) Dew point temperature(°C)   Solar Radiation (MJ/m2) \n                        0                         0                         0 \n             Rainfall(mm)             Snowfall (cm)                   Seasons \n                        0                         0                         0 \n                  Holiday           Functioning Day \n                        0                         0 \n\n\nWe see from the output that there are no missing values in any of the columns.\nSteps 2 through 4. We combine steps 2 through 4. First, we check the data type for each column. We first print the tibble to view this.\n\nrentals\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\nWe note that the date is in character form, which is not ideal. We fix this now by using the lubridate package to transform the date column into Date-type data.\n\nrentals &lt;- rentals |&gt;\n  mutate(Date = dmy(Date))\n\nReviewing the data description, the quantitative variables appear to be Rented Bike Count, Hour, Temperature, Humidity, Wind speed, Visibility, Dew point temperature, Solar Radiation, Rainfall, and Snowfall. All of these quantitative variables are already stored as doubles, so we don’t need to make a change here. We will view their summary stats to make sure the numbers make sense. Note range.1 is the minimum and range.2 is the maximum, respectively, of an observation.\n\nrentals_numeric &lt;- rentals |&gt;\n  select(where(is.numeric)) |&gt;\n  as.matrix()\n\ndata.frame('mean' = colMeans(rentals_numeric),\n'median' = colMedians(rentals_numeric),\n'sd' = colSds(rentals_numeric),\n'IQR' = colIQRs(rentals_numeric),\n'range' = colRanges(rentals_numeric)) |&gt;\n  round(1) \n\n                            mean median    sd    IQR range.1 range.2\nRented Bike Count          704.6  504.5 645.0  874.2     0.0  3556.0\nHour                        11.5   11.5   6.9   11.5     0.0    23.0\nTemperature(°C)             12.9   13.7  11.9   19.0   -17.8    39.4\nHumidity(%)                 58.2   57.0  20.4   32.0     0.0    98.0\nWind speed (m/s)             1.7    1.5   1.0    1.4     0.0     7.4\nVisibility (10m)          1436.8 1698.0 608.3 1060.0    27.0  2000.0\nDew point temperature(°C)    4.1    5.1  13.1   19.5   -30.6    27.2\nSolar Radiation (MJ/m2)      0.6    0.0   0.9    0.9     0.0     3.5\nRainfall(mm)                 0.1    0.0   1.1    0.0     0.0    35.0\nSnowfall (cm)                0.1    0.0   0.4    0.0     0.0     8.8\n\n\nLooking at the summary statistics for numeric variables, all of the results appear appropriate for what they represent.\nThe categorical variables appear to be Seasons, Holiday, and Functioning Day. They are stored as data type character. We convert them to factors.\n\nrentals &lt;- rentals |&gt;\n  mutate(Seasons = as.factor(Seasons),\n         Holiday = as.factor(Holiday),\n         `Functioning Day` = as.factor(`Functioning Day`))\n\nNow it is easy to check the unique values and counts for the categorical variables.\n\nrentals |&gt;\n  select(where(is.factor)) |&gt;\n  summary()\n\n   Seasons           Holiday     Functioning Day\n Autumn:2184   Holiday   : 432   No : 295       \n Spring:2208   No Holiday:8328   Yes:8465       \n Summer:2208                                    \n Winter:2160                                    \n\n\nStep 5. In this step, we rename the variables so they have easy to use names which follow R naming conventions.\n\nrentals &lt;- rentals |&gt;\n  rename('date' = 'Date',\n         'rented_bike_count' = 'Rented Bike Count',\n         'hour' = 'Hour',\n         'temperature' = 'Temperature(°C)',\n         'humidity' = 'Humidity(%)',\n         'wind_speed' = 'Wind speed (m/s)',\n         'visibility' = 'Visibility (10m)',\n         'dew_point_temp' = 'Dew point temperature(°C)',\n         'solar_radiation' = 'Solar Radiation (MJ/m2)',\n         'rainfall' = 'Rainfall(mm)',\n         'snowfall' = 'Snowfall (cm)',\n         'seasons' = 'Seasons',\n         'holiday' = 'Holiday',\n         'functioning_day' = 'Functioning Day')\n\nStep 6. Now we perform summary statistics.\nFirst we perform numerical summaries for quantitative variables without grouping by any categorical variables. We can copy the code from step 2 since we did this already. Note range.1 is the minimum and range.2 is the maximum, respectively, of an observation.\n\nrentals_numeric &lt;- rentals |&gt;\n  select(where(is.numeric)) |&gt;\n  as.matrix()\n\ndata.frame('mean' = colMeans(rentals_numeric),\n'median' = colMedians(rentals_numeric),\n'sd' = colSds(rentals_numeric),\n'IQR' = colIQRs(rentals_numeric),\n'range' = colRanges(rentals_numeric)) |&gt;\n  round(1) \n\n                    mean median    sd    IQR range.1 range.2\nrented_bike_count  704.6  504.5 645.0  874.2     0.0  3556.0\nhour                11.5   11.5   6.9   11.5     0.0    23.0\ntemperature         12.9   13.7  11.9   19.0   -17.8    39.4\nhumidity            58.2   57.0  20.4   32.0     0.0    98.0\nwind_speed           1.7    1.5   1.0    1.4     0.0     7.4\nvisibility        1436.8 1698.0 608.3 1060.0    27.0  2000.0\ndew_point_temp       4.1    5.1  13.1   19.5   -30.6    27.2\nsolar_radiation      0.6    0.0   0.9    0.9     0.0     3.5\nrainfall             0.1    0.0   1.1    0.0     0.0    35.0\nsnowfall             0.1    0.0   0.4    0.0     0.0     8.8\n\n\nNext we create one- and two-way contingency tables to summarize our categorical variables.\n\ntable(rentals$seasons)\n\n\nAutumn Spring Summer Winter \n  2184   2208   2208   2160 \n\ntable(rentals$holiday)\n\n\n   Holiday No Holiday \n       432       8328 \n\ntable(rentals$functioning_day)\n\n\n  No  Yes \n 295 8465 \n\ntable(rentals$seasons, rentals$holiday)\n\n        \n         Holiday No Holiday\n  Autumn     120       2064\n  Spring      72       2136\n  Summer      48       2160\n  Winter     192       1968\n\ntable(rentals$seasons, rentals$functioning_day)\n\n        \n           No  Yes\n  Autumn  247 1937\n  Spring   48 2160\n  Summer    0 2208\n  Winter    0 2160\n\ntable(rentals$holiday, rentals$functioning_day)\n\n            \n               No  Yes\n  Holiday      24  408\n  No Holiday  271 8057\n\n\nNext we will create numerical summaries for the Bike Rental Count across the different categorical variables. We will do it separately for each categorical variable. Then we do it grouped by all categorical variables at once.\n\nrentals |&gt;\n  group_by(functioning_day) |&gt;\n  summarize(across(rented_bike_count,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n  functioning_day rented_bike_count_mean rented_bike_count_median\n1              No                  0.000                        0\n2             Yes                729.157                      542\n  rented_bike_count_sd rented_bike_count_IQR rented_bike_count_min\n1               0.0000                     0                     0\n2             642.3512                   870                     2\n  rented_bike_count_max\n1                     0\n2                  3556\n\nrentals |&gt;\n  group_by(seasons) |&gt;\n  summarize(across(rented_bike_count,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n  seasons rented_bike_count_mean rented_bike_count_median rented_bike_count_sd\n1  Autumn               819.5980                    763.5             651.0856\n2  Spring               730.0312                    583.0             621.5096\n3  Summer              1034.0734                    905.5             690.2448\n4  Winter               225.5412                    203.0             150.3722\n  rented_bike_count_IQR rented_bike_count_min rented_bike_count_max\n1                955.75                     0                  3298\n2                899.25                     0                  3251\n3                915.75                     9                  3556\n4                195.00                     3                   937\n\nrentals |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(rented_bike_count,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n     holiday rented_bike_count_mean rented_bike_count_median\n1    Holiday               499.7569                    240.0\n2 No Holiday               715.2280                    524.5\n  rented_bike_count_sd rented_bike_count_IQR rented_bike_count_min\n1             570.7728                656.75                     0\n2             646.8791                873.00                     0\n  rented_bike_count_max\n1                  2400\n2                  3556\n\nrentals |&gt;\n  group_by(functioning_day, seasons, holiday) |&gt;\n  summarize(across(rented_bike_count,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n`summarise()` has grouped output by 'functioning_day', 'seasons'. You can\noverride using the `.groups` argument.\n\n\n   functioning_day seasons    holiday rented_bike_count_mean\n1               No  Autumn    Holiday                 0.0000\n2               No  Autumn No Holiday                 0.0000\n3               No  Spring No Holiday                 0.0000\n4              Yes  Autumn    Holiday               948.1042\n5              Yes  Autumn No Holiday               922.8593\n6              Yes  Spring    Holiday               635.3056\n7              Yes  Spring No Holiday               750.0800\n8              Yes  Summer    Holiday              1022.1458\n9              Yes  Summer No Holiday              1034.3384\n10             Yes  Winter    Holiday               156.6250\n11             Yes  Winter No Holiday               232.2647\n   rented_bike_count_median rented_bike_count_sd rented_bike_count_IQR\n1                       0.0               0.0000                  0.00\n2                       0.0               0.0000                  0.00\n3                       0.0               0.0000                  0.00\n4                     900.0             603.4026                973.25\n5                     852.0             618.4115                833.00\n6                     366.5             608.9188                869.50\n7                     605.0             618.7902                890.50\n8                     925.0             564.3735                848.25\n9                     904.5             692.8875                918.00\n10                    138.0             107.5129                150.00\n11                    212.0             152.2752                196.25\n   rented_bike_count_min rented_bike_count_max\n1                      0                     0\n2                      0                     0\n3                      0                     0\n4                    105                  2400\n5                      2                  3298\n6                     11                  2082\n7                      2                  3251\n8                    218                  2163\n9                      9                  3556\n10                     3                   671\n11                     7                   937\n\n\nAs an example of what we can do with this information, we note that Rented Bike Counts are highest during the summer, and that in the summer the count doesn’t seem to be affected by whether the day is a holiday, as long as it is a functioning day.\nWe see from the output that no bikes are rented when the Functioning Day variable takes a value of ‘No’. Therefore it makes sense to remove these observations from the tibble, since in this homework the response variable we are interested in is the Rented Bike Count.\n\nrentals &lt;- rentals |&gt;\n  filter(functioning_day != 'No')\n\nNow we use the subsetted data for the rest of the homework.\nStep 7. In this step, we create a new data tibble by summarizing across all hours of the day. This will simplify the data since each date will have one observation. The new tibble will not have an hours column since we are summarizing across the whole day, and it will not have a Functioning Day column since we removed the “No” observations previously, so all remaining values are “Yes” observations.\n\nrentals_condensed &lt;- rentals |&gt; \n  group_by(date, seasons, holiday) |&gt;\n  mutate(bike_count_daily = sum(rented_bike_count),\n         rainfall_daily = sum(rainfall),\n         snowfall_daily = sum(snowfall),\n         temp_mean = mean(temperature),\n         humidity_mean = mean(humidity),\n         wind_speed_mean = mean(wind_speed),\n         visibility_mean = mean(visibility),\n         dew_point_temp_mean = mean(dew_point_temp),\n         solar_radiation_mean = mean(solar_radiation)) |&gt;\n  select(date, seasons, holiday, bike_count_daily, rainfall_daily, snowfall_daily, temp_mean, humidity_mean, wind_speed_mean, visibility_mean, dew_point_temp_mean, solar_radiation_mean) |&gt;\n  unique() |&gt;\n  ungroup()\n\nWe can view the first few rows to get a feel for our new data table.\n\nhead(as.data.frame(rentals_condensed))\n\n        date seasons    holiday bike_count_daily rainfall_daily snowfall_daily\n1 2017-12-01  Winter No Holiday             9539            0.0            0.0\n2 2017-12-02  Winter No Holiday             8523            0.0            0.0\n3 2017-12-03  Winter No Holiday             7222            4.0            0.0\n4 2017-12-04  Winter No Holiday             8729            0.1            0.0\n5 2017-12-05  Winter No Holiday             8307            0.0            0.0\n6 2017-12-06  Winter No Holiday             6669            1.3            8.6\n    temp_mean humidity_mean wind_speed_mean visibility_mean dew_point_temp_mean\n1 -2.45416667      45.87500       1.5375000        1870.750          -13.545833\n2  1.32500000      61.95833       1.7125000        1471.083           -5.716667\n3  4.87500000      81.54167       1.6125000         455.750            1.883333\n4 -0.30416667      52.50000       3.4500000        1362.833           -9.925000\n5 -4.45833333      36.41667       1.1083333        1959.458          -17.425000\n6  0.04583333      70.79167       0.6958333        1186.875           -5.187500\n  solar_radiation_mean\n1           0.24875000\n2           0.26375000\n3           0.12541667\n4           0.28291667\n5           0.03583333\n6           0.25583333\n\n\nStep 8. We will redo basic summary stats with the new data, and we make some plots to explore the data. First we determine the summary stats without grouping by any categorical variables.\n\nrentals_condensed_numeric &lt;- rentals_condensed |&gt;\n  select(where(is.numeric)) |&gt;\n  as.matrix()\n\ndata.frame('mean' = colMeans(rentals_condensed_numeric),\n'median' = colMedians(rentals_condensed_numeric),\n'sd' = colSds(rentals_condensed_numeric),\n'IQR' = colIQRs(rentals_condensed_numeric),\n'range' = colRanges(rentals_condensed_numeric)) |&gt;\n  round(1) \n\n                        mean  median     sd     IQR range.1 range.2\nbike_count_daily     17485.3 18563.0 9937.2 19318.0   977.0 36149.0\nrainfall_daily           3.6     0.0   11.8     0.5     0.0    95.5\nsnowfall_daily           1.9     0.0    8.8     0.0     0.0    78.7\ntemp_mean               12.8    13.7   11.7    19.3   -14.7    33.7\nhumidity_mean           58.2    57.2   14.9    20.1    22.2    95.9\nwind_speed_mean          1.7     1.7    0.6     0.6     0.7     4.0\nvisibility_mean       1434.0  1557.8  491.2   787.2   214.3  2000.0\ndew_point_temp_mean      4.0     4.6   13.0    20.1   -27.8    25.0\nsolar_radiation_mean     0.6     0.6    0.3     0.5     0.0     1.2\n\n\nNext we determine the summary stats for daily bike rental count with grouping by categorical variables as we did in Step 6. Since we removed the Functional Day variable for reasons discussed above, we will not include this in the grouping.\n\nrentals_condensed |&gt;\n  group_by(seasons) |&gt;\n  summarize(across(bike_count_daily,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n  seasons bike_count_daily_mean bike_count_daily_median bike_count_daily_sd\n1  Autumn             22098.790                 23350.0            6710.893\n2  Spring             17910.100                 17590.0            8357.149\n3  Summer             24817.761                 25571.5            7297.344\n4  Winter              5412.989                  5498.0            1808.340\n  bike_count_daily_IQR bike_count_daily_min bike_count_daily_max\n1             10733.00                 1721                31809\n2             14361.75                  977                31681\n3              9308.50                 3231                36149\n4              2633.75                 2014                 9539\n\nrentals_condensed |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(bike_count_daily,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n     holiday bike_count_daily_mean bike_count_daily_median bike_count_daily_sd\n1    Holiday              12699.71                  7184.0           10504.342\n2 No Holiday              17727.44                 19104.5            9862.417\n  bike_count_daily_IQR bike_count_daily_min bike_count_daily_max\n1             16576.00                 2014                30498\n2             19167.75                  977                36149\n\nrentals_condensed |&gt;\n  group_by(seasons, holiday) |&gt;\n  summarize(across(bike_count_daily,\n            list('mean' = ~mean(.x),\n                 'median' = ~median(.x),\n                 'sd' = ~sd(.x),\n                 'IQR' = ~IQR(.x),\n                 'min' = ~min(.x),\n                 'max' = ~max(.x)),\n            .names = \"{.col}_{.fn}\")) |&gt;\n  as.data.frame()\n\n`summarise()` has grouped output by 'seasons'. You can override using the\n`.groups` argument.\n\n\n  seasons    holiday bike_count_daily_mean bike_count_daily_median\n1  Autumn    Holiday             22754.500                 21705.0\n2  Autumn No Holiday             22064.727                 23472.0\n3  Spring    Holiday             15247.333                 13790.0\n4  Spring No Holiday             18001.920                 17730.0\n5  Summer    Holiday             24531.500                 24531.5\n6  Summer No Holiday             24824.122                 25571.5\n7  Winter    Holiday              3759.000                  3453.5\n8  Winter No Holiday              5574.354                  5609.0\n  bike_count_daily_sd bike_count_daily_IQR bike_count_daily_min\n1            5641.864              5740.00                17259\n2            6791.622             10734.00                 1721\n3           10917.198             10844.00                 5132\n4            8321.699             14223.50                  977\n5            8437.905              5966.50                18565\n6            7324.345              9165.00                 3231\n7            1561.108              1060.25                 2014\n8            1756.674              2564.00                 2487\n  bike_count_daily_max\n1                30349\n2                31809\n3                26820\n4                31681\n5                30498\n6                36149\n7                 7184\n8                 9539\n\n\nAn interesting observation from this output is that in the Spring, mean daily bike rental count is lower on holidays than on non-holidays. However, in the summer, the mean daily bike rental count appears to be nearly the same on holidays and non-holidays. While we would need to conduct hypothesis testing to be more confident about this relationship, it seems that holidays which occur during the summer don’t dissuade people from renting bikes, whereas holidays which occur in the spring do dissuade people from renting bikes.\nNext we create some plots. An interesting start would be to summarize graphically what we discussed in the previous paragraph and view the summaries of daily bike rental counts by season and holidays.\n\nrentals_condensed |&gt;\n  ggplot(aes(x = holiday, y = bike_count_daily)) + geom_boxplot() + facet_wrap(~seasons) + labs(x = 'Holiday Status', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count Summaries by Holiday Status and Season')\n\n\n\n\n\n\n\n\nThis depicts graphically what we noted from the numerical summaries. In the spring, fewer rentals occur on holidays, while in the summer, the difference between holidays and non-holidays is less pronounced.\nNext we will view daily bike rental counts over the course of the year.\n\nrentals_condensed |&gt;\n  ggplot(aes(x = date, y = bike_count_daily)) + geom_point() + labs(x = 'Date', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count by Date')\n\n\n\n\n\n\n\n\nWe see from the output that far fewer rentals occur in the winter, they start to rise around March-April, and they peak around July. Then there is another peak in the fall around October. It is also interesting to note that the variability in rentals is higher in the peak seasons and lower in the winter. These results make intuitive sense. Summer and Fall are nice times to ride. The winter can be uncomfortable.\nIn that spirit, we next make a plot of temperature versus rental count. We would expect in general that bike rental counts are higher on warmer days. Let’s see.\n\nrentals_condensed |&gt;\n  ggplot(aes(x = temp_mean, y = bike_count_daily)) + geom_point() + labs(x = 'Average Daily Temperature', y = 'Daily Bike Rental Count', title = 'Daily Bike Rental Count vs. Average Daily Temperature')\n\n\n\n\n\n\n\n\nAs expected, we see that bike rental counts tend to be higher on warmer days. However, we do see that at the high extreme of temperature, rentals start to decline. People are less likely to ride when it is too hot.\nFinally let’s take a look at correlation between numeric variables. We will view the results in a correlation matrix for easy viewing.\n\nggcorrplot(cor(rentals_condensed_numeric))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggcorrplot package.\n  Please report the issue at &lt;https://github.com/kassambara/ggcorrplot/issues&gt;.\n\n\n\n\n\n\n\n\n\nThese correlations make sense. As discussed before based on our plot, daily bike rental count correlates positively with average daily temperature. And as one would expect, daily bike rental count correlates negatively with average wind speed, daily rainfall, and daily snowfall."
  },
  {
    "objectID": "Homework9.html#splitting-data",
    "href": "Homework9.html#splitting-data",
    "title": "Homework 9",
    "section": "Splitting Data",
    "text": "Splitting Data\nNow that we have wrangled the data and done some EDA, it is time to begin modeling. In this section we split the data into training and test sets using a 75/25 split, stratifying on the seasons variable.\n\nset.seed(438)\nrentals_condensed_split &lt;- initial_split(rentals_condensed, prop = 0.75, strata = seasons)\nrentals_condensed_train &lt;- training(rentals_condensed_split)\nrentals_condensed_test &lt;- testing(rentals_condensed_split)\n\nNow on the training set, we create a 10-fold CV split.\n\nset.seed(200)\nrentals_10_fold &lt;- vfold_cv(rentals_condensed_train, 10)"
  },
  {
    "objectID": "Homework9.html#fitting-three-mlr-models",
    "href": "Homework9.html#fitting-three-mlr-models",
    "title": "Homework 9",
    "section": "Fitting Three MLR Models",
    "text": "Fitting Three MLR Models\nIn this section, we fit 3 MLR models on the training data using 10-fold cross validation and pick a best model on the training data.\nWe begin by creating 3 recipes as outlined in the homework instructions. For the first recipe we use the date variable to create a weekend/weekday categorical (factor) variable which replaces the date variable, standardize the numeric variables, and create dummy variables for the categorical variables (seasons, holiday, and new weekend/weekday variable). First we will use prep() and bake() to print the transformed data as a sanity check.\n\nrecipe(bike_count_daily ~., data = rentals_condensed_train) |&gt;\n  step_date(date, features = 'dow') |&gt;\n  step_mutate(weekend = factor(ifelse(\n    date_dow %in% c('Sat', 'Sun'),\n    'Yes',\n    'No'\n  ))) |&gt;\n  step_rm(date_dow) |&gt;\n  update_role(date, new_role = 'Date') |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(holiday, seasons, weekend) |&gt;\n  prep(training = rentals_condensed_train) |&gt;\n  bake(rentals_condensed_train)\n\n# A tibble: 263 × 15\n   date       rainfall_daily snowfall_daily temp_mean humidity_mean\n   &lt;date&gt;              &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 2018-09-01         -0.316         -0.227     1.09          0.165\n 2 2018-09-03          2.61          -0.227     0.927         1.56 \n 3 2018-09-04         -0.316         -0.227     0.897         0.854\n 4 2018-09-06         -0.316         -0.227     0.982         0.799\n 5 2018-09-08         -0.316         -0.227     0.762        -0.664\n 6 2018-09-09         -0.316         -0.227     0.785        -0.611\n 7 2018-09-11         -0.316         -0.227     0.751        -0.710\n 8 2018-09-12         -0.316         -0.227     0.834        -0.449\n 9 2018-09-13         -0.316         -0.227     0.913         0.237\n10 2018-09-15         -0.299         -0.227     0.893         1.13 \n# ℹ 253 more rows\n# ℹ 10 more variables: wind_speed_mean &lt;dbl&gt;, visibility_mean &lt;dbl&gt;,\n#   dew_point_temp_mean &lt;dbl&gt;, solar_radiation_mean &lt;dbl&gt;,\n#   bike_count_daily &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;, seasons_Spring &lt;dbl&gt;,\n#   seasons_Summer &lt;dbl&gt;, seasons_Winter &lt;dbl&gt;, weekend_Yes &lt;dbl&gt;\n\n\nThe result looks good, so we save the recipe in a recipe object, which is what we actually need for fitting the model.\n\nrentals_rec1 &lt;- recipe(bike_count_daily ~., data = rentals_condensed_train) |&gt;\n  step_date(date, features = 'dow') |&gt;\n  step_mutate(weekend = factor(ifelse(\n    date_dow %in% c('Sat', 'Sun'),\n    'Yes',\n    'No'\n  ))) |&gt;\n  step_rm(date_dow) |&gt;\n  update_role(date, new_role = 'Date') |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(holiday, seasons, weekend)\n\nTo create the second recipe, we use the same steps as above but we add in interaction terms between seasons and holiday, seasons and temperature, and temperature and rainfall.\n\nrentals_rec2 &lt;- recipe(bike_count_daily ~., data = rentals_condensed_train) |&gt;\n  step_date(date, features = 'dow') |&gt;\n  step_mutate(weekend = factor(ifelse(\n    date_dow %in% c('Sat', 'Sun'),\n    'Yes',\n    'No'\n  ))) |&gt;\n  step_rm(date_dow) |&gt;\n  update_role(date, new_role = 'Date') |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(holiday, seasons, weekend) |&gt;\n  step_interact(terms = ~ starts_with('seasons'):holiday_No.Holiday + starts_with('seasons'):temp_mean + temp_mean:rainfall_daily) \n\nFinally, for the third recipe, we do the same as for the second recipe but add in quadratic terms for each numeric predictor.\n\nrentals_rec3 &lt;- recipe(bike_count_daily ~., data = rentals_condensed_train) |&gt;\n  step_date(date, features = 'dow') |&gt;\n  step_mutate(weekend = factor(ifelse(\n    date_dow %in% c('Sat', 'Sun'),\n    'Yes',\n    'No'\n  ))) |&gt;\n  step_rm(date_dow) |&gt;\n  update_role(date, new_role = 'Date') |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_poly(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(holiday, seasons, weekend) |&gt;\n  step_interact(terms = ~ starts_with('seasons'):holiday_No.Holiday + starts_with('seasons'):temp_mean_poly_1 + temp_mean_poly_1:rainfall_daily_poly_1) \n\nNow we set up the model using the linear model engine and use fit_resamples() to fit the models.\n\nrentals_mod &lt;- linear_reg() %&gt;% \n  set_engine('lm')\n\nrentals_CV_wkfl1 &lt;- workflow() |&gt;\n  add_recipe(rentals_rec1) |&gt;\n  add_model(rentals_mod) \n\nrentals_CV_wkfl2 &lt;- workflow() |&gt;\n  add_recipe(rentals_rec2) |&gt;\n  add_model(rentals_mod) \n\nrentals_CV_wkfl3 &lt;- workflow() |&gt;\n  add_recipe(rentals_rec3) |&gt;\n  add_model(rentals_mod) \n\nrentals_CV_fit1 &lt;- fit_resamples(rentals_CV_wkfl1, rentals_10_fold)\n\nrentals_CV_fit2 &lt;- fit_resamples(rentals_CV_wkfl2, rentals_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nrentals_CV_fit3 &lt;- fit_resamples(rentals_CV_wkfl3, rentals_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n\nFinally, we can view the training set metrics for each model to compare models and determine which to use for the final fitting.\n\nrbind(rentals_CV_fit1 |&gt; collect_metrics(),\n      rentals_CV_fit2 |&gt; collect_metrics(),\n      rentals_CV_fit3 |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n  std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   4240.       10 176.     pre0_mod0_post0\n2 rsq     standard      0.830    10   0.0141 pre0_mod0_post0\n3 rmse    standard   3201.       10 179.     pre0_mod0_post0\n4 rsq     standard      0.901    10   0.0112 pre0_mod0_post0\n5 rmse    standard   3092.       10 191.     pre0_mod0_post0\n6 rsq     standard      0.906    10   0.0124 pre0_mod0_post0\n\n\nWe see that the third model has the lowest training set RMSE, so we will choose this as our optimal model. We fit this model to the whole training set in the next step."
  },
  {
    "objectID": "Homework9.html#fitting-and-testing-best-model",
    "href": "Homework9.html#fitting-and-testing-best-model",
    "title": "Homework 9",
    "section": "Fitting and Testing Best Model",
    "text": "Fitting and Testing Best Model\nNow that we have chosen the ‘best’ model (the third) as the one with the lowest training set RMSE, we fit this model to the full training set and print the test set RMSE.\n\nrentals_fit_final &lt;- rentals_CV_wkfl3 |&gt;\n  last_fit(rentals_condensed_split, metrics = metric_set(rmse, mae))\n\nrentals_fit_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       2531. pre0_mod0_post0\n2 mae     standard       1999. pre0_mod0_post0\n\n\nWe also obtain the final table of coefficients for the model.\n\nrentals_fit_final |&gt;\n  extract_fit_parsnip()  |&gt;\n  tidy() |&gt;\n  print(n = 30)\n\n# A tibble: 29 × 5\n   term                                    estimate std.error statistic  p.value\n   &lt;chr&gt;                                      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                               16273.     1722.     9.45  3.74e-18\n 2 rainfall_daily_poly_1                    -29082.     6758.    -4.30  2.47e- 5\n 3 rainfall_daily_poly_2                     10579.     3452.     3.06  2.44e- 3\n 4 snowfall_daily_poly_1                      -805.     3517.    -0.229 8.19e- 1\n 5 snowfall_daily_poly_2                     -2563.     3323.    -0.771 4.41e- 1\n 6 temp_mean_poly_1                          27585.    76262.     0.362 7.18e- 1\n 7 temp_mean_poly_2                         -10511.    19704.    -0.533 5.94e- 1\n 8 humidity_mean_poly_1                     -27287.    27164.    -1.00  3.16e- 1\n 9 humidity_mean_poly_2                      -6417.     6698.    -0.958 3.39e- 1\n10 wind_speed_mean_poly_1                    -9615.     3445.    -2.79  5.68e- 3\n11 wind_speed_mean_poly_2                     2045.     3316.     0.617 5.38e- 1\n12 visibility_mean_poly_1                     3296.     4520.     0.729 4.67e- 1\n13 visibility_mean_poly_2                     -740.     3208.    -0.231 8.18e- 1\n14 dew_point_temp_mean_poly_1                70246.    89109.     0.788 4.31e- 1\n15 dew_point_temp_mean_poly_2                -1474.    12747.    -0.116 9.08e- 1\n16 solar_radiation_mean_poly_1               47340.     6124.     7.73  3.15e-13\n17 solar_radiation_mean_poly_2              -10059.     3839.    -2.62  9.36e- 3\n18 holiday_No.Holiday                         5768.     1566.     3.68  2.85e- 4\n19 seasons_Spring                            -1855.     2432.    -0.763 4.46e- 1\n20 seasons_Summer                            18525.     3889.     4.76  3.35e- 6\n21 seasons_Winter                            -7580.     2961.    -2.56  1.11e- 2\n22 weekend_Yes                               -2111.      425.    -4.96  1.33e- 6\n23 seasons_Spring_x_holiday_No.Holiday       -2733.     2489.    -1.10  2.73e- 1\n24 seasons_Summer_x_holiday_No.Holiday       -3459.     3407.    -1.02  3.11e- 1\n25 seasons_Winter_x_holiday_No.Holiday       -3454.     2080.    -1.66  9.81e- 2\n26 seasons_Spring_x_temp_mean_poly_1         95906.    19689.     4.87  2.05e- 6\n27 seasons_Summer_x_temp_mean_poly_1       -259190.    41047.    -6.31  1.35e- 9\n28 seasons_Winter_x_temp_mean_poly_1        -65145.    48550.    -1.34  1.81e- 1\n29 temp_mean_poly_1_x_rainfall_daily_poly… -424766.   135272.    -3.14  1.91e- 3"
  },
  {
    "objectID": "Homework9.html#start-of-homework-9",
    "href": "Homework9.html#start-of-homework-9",
    "title": "Homework 9",
    "section": "Start of Homework 9",
    "text": "Start of Homework 9\nHere we add additional modeling to complete the requirements for homework 9. Prior to this point, everything we had done is copied directly from homework 8."
  },
  {
    "objectID": "Homework9.html#lasso-model",
    "href": "Homework9.html#lasso-model",
    "title": "Homework 9",
    "section": "LASSO Model",
    "text": "LASSO Model\nIn this section we fit a tuned LASSO model to the training set using cross-validation to choose the tuning parameter. From the material we completed for homework 8, we already have a training-test split, CV folds, and recipe. So our first step is to create a model with an engine and a workflow.\n\nLASSO_mod &lt;- linear_reg(penalty = tune(), mixture = 1) |&gt;\n  set_engine('glmnet')\n\nLASSO_wkfl &lt;- workflow() |&gt;\n  add_recipe(rentals_rec1) |&gt;\n  add_model(LASSO_mod)\n\nNext we fit the model for many different candidates of the tuning parameter using cross-validation and select the best value for the tuning parameter to fit on the training set.\n\nLASSO_grid &lt;- LASSO_wkfl |&gt;\n  tune_grid(resamples = rentals_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\n\nLASSO_parameter_best &lt;- LASSO_grid |&gt;\n  select_best(metric = 'rmse')\n\nNow that we have determined the best model by finding the tuning parameter which yields the lowest training set cross-validation RMSE, we fit this model to the entire training set and find its metrics on the test set. Later in this assignment, we will assemble the test set metrics from all our different models into one table.\n\nLASSO_fit_final &lt;- LASSO_wkfl |&gt;\n  finalize_workflow(LASSO_parameter_best) |&gt;\n  last_fit(rentals_condensed_split, metrics = metric_set(rmse, mae)) \n\nLASSO_fit_final |&gt; \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       3819. pre0_mod0_post0\n2 mae     standard       3001. pre0_mod0_post0"
  },
  {
    "objectID": "Homework9.html#regression-tree-model",
    "href": "Homework9.html#regression-tree-model",
    "title": "Homework 9",
    "section": "Regression Tree Model",
    "text": "Regression Tree Model\nNext we fit a regression tree model to predict bike rental count. Again, from the material we completed for homework 8 we already have a training-test split, CV folds, and recipe. Therefore we start by creating a model with engine and a workflow.\n\n# we are tuning on tree depth and cost complexity ---\ntree_model &lt;- decision_tree(tree_depth = tune(),\n                            min_n = 20,\n                            cost_complexity = tune()) |&gt;\n  set_engine('rpart') |&gt;\n  set_mode('regression')\n\ntree_wkfl &lt;- workflow() |&gt;\n  add_recipe(rentals_rec1) |&gt;\n  add_model(tree_model)\n\nNext we fit the model for many different candidates of the tuning parameters using cross-validation and select the best value for the tuning parameter to fit on the training set.\n\ntree_grid &lt;- tree_wkfl |&gt;\n  tune_grid(resamples = rentals_10_fold,\n            grid = grid_regular(tree_depth(), cost_complexity(), levels = c(5, 10))) \n\ntree_parameter_best &lt;- tree_grid |&gt; select_best(metric = 'rmse')\n\nAs we did with the LASSO model, now that we have determined the best model by finding the tuning parameters which yield the lowest training set cross-validation RMSE, we fit this model to the entire training set and find its metrics on the test set.\n\ntree_fit_final &lt;- tree_wkfl |&gt;\n  finalize_workflow(tree_parameter_best) |&gt;\n  last_fit(rentals_condensed_split, metrics = metric_set(rmse, mae)) \n\ntree_fit_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       3651. pre0_mod0_post0\n2 mae     standard       2757. pre0_mod0_post0"
  },
  {
    "objectID": "Homework9.html#bagged-tree-model",
    "href": "Homework9.html#bagged-tree-model",
    "title": "Homework 9",
    "section": "Bagged Tree Model",
    "text": "Bagged Tree Model\nWe repeat the same sequence of steps as we did for the LASSO and regression tree models to create a bagged tree model. Since the sequence of steps for doing so is exactly the same as previous models, we will not repeat the narrative description again. Comments are included for clarity.\n\nset.seed(366)\n\n# set up model with engine. we tune only on cost complexity here ----\nbagg_mod &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) |&gt;\n  set_engine('rpart') |&gt;\n  set_mode('regression')\n\n# set up workflow ----\nbagg_wkfl &lt;- workflow() |&gt;\n  add_recipe(rentals_rec1) |&gt;\n  add_model(bagg_mod)\n\n# fit many different models at varying levels of cost complexity using 10-fold cross validation ----\nbagg_grid &lt;- bagg_wkfl |&gt;\n  tune_grid(resamples = rentals_10_fold,\n            grid = grid_regular(\n              cost_complexity(),\n              levels = 15\n            ))\n\nRegistered S3 method overwritten by 'butcher':\n  method                 from    \n  as.character.dev_topic generics\n\n\n→ A | warning: There was 1 warning in `dplyr::mutate()`.\n               ℹ In argument: `model = iter(...)`.\n               Caused by warning:\n               ! package 'future' was built under R version 4.5.2\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n# select the model with the lowest training set cross validation rmse and extract the value for the parameter which achieves this. in this case we tuned only on cost complexity so this is the only parameter to extract ----\nbagg_parameter_best &lt;- bagg_grid |&gt;\n  select_best(metric = 'rmse')\n\n# use the best parameter to fit the best model on the whole training set ----\nbagg_fit_final &lt;- bagg_wkfl |&gt;\n  finalize_workflow(bagg_parameter_best) |&gt;\n  last_fit(rentals_condensed_split, metrics = metric_set(rmse, mae)) \n\n# extract test set metrics ---\nbagg_fit_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       2735. pre0_mod0_post0\n2 mae     standard       2135. pre0_mod0_post0"
  },
  {
    "objectID": "Homework9.html#random-forest-model",
    "href": "Homework9.html#random-forest-model",
    "title": "Homework 9",
    "section": "Random Forest Model",
    "text": "Random Forest Model\nWe repeat the same sequence of steps as we did for the LASSO, regression tree, and bagged tree models to create a random forest model. Since the sequence of steps for doing so is exactly the same as previous models, we will not repeat the narrative description again. Comments are included for clarity.\n\nset.seed(4000)\n\n# create a model. tune on number of features to consider at each split ----\nrf_mod &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine('ranger') |&gt;\n  set_mode('regression')\n\n# create a workflow\nrf_wkfl &lt;- workflow() |&gt;\n  add_recipe(rentals_rec1) |&gt;\n  add_model(rf_mod)\n\n# fit diffent models at various levels of mtry using 10 fold cv and choose best value for mtry to use in final model on training data ----\nrf_grid &lt;- rf_wkfl |&gt;\n  tune_grid(resamples = rentals_10_fold)\n\ni Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n\nrf_parameter_best &lt;- rf_grid |&gt;\n  select_best(metric = 'rmse')\n\n# use best value for parameter to fit the best random forest model to the full training data set and extract test set metrics\nrf_fit_final &lt;- rf_wkfl |&gt;\n  finalize_workflow(rf_parameter_best) |&gt;\n  last_fit(rentals_condensed_split, metrics = metric_set(rmse, mae))\n\nrf_fit_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard       2427. pre0_mod0_post0\n2 mae     standard       1871. pre0_mod0_post0"
  },
  {
    "objectID": "Homework9.html#model-comparison",
    "href": "Homework9.html#model-comparison",
    "title": "Homework 9",
    "section": "Model Comparison",
    "text": "Model Comparison\nIn this step, we compare the test set metrics for all models (best MLR model from HW8, LASSO, regression tree, bagged tree, random forest) to see which model performs best on the test set. We assemble the metrics into a tibble so we can easily compare.\n\nrbind(rentals_fit_final |&gt; collect_metrics(),\n      LASSO_fit_final |&gt; collect_metrics(),\n      tree_fit_final |&gt; collect_metrics(),\n      bagg_fit_final |&gt; collect_metrics(),\n      rf_fit_final |&gt; collect_metrics()) |&gt;\n  mutate(names = c('MLR', 'MLR', 'LASSO', 'LASSO', 'Regression Tree', 'Regression Tree', 'Bagged Tree', 'Bagged Tree', 'Random Forest', 'Random Forest')) |&gt;\n  select(names, .metric, .estimate) |&gt;\n  arrange(.metric, .estimate)\n\n# A tibble: 10 × 3\n   names           .metric .estimate\n   &lt;chr&gt;           &lt;chr&gt;       &lt;dbl&gt;\n 1 Random Forest   mae         1871.\n 2 MLR             mae         1999.\n 3 Bagged Tree     mae         2135.\n 4 Regression Tree mae         2757.\n 5 LASSO           mae         3001.\n 6 Random Forest   rmse        2427.\n 7 MLR             rmse        2531.\n 8 Bagged Tree     rmse        2735.\n 9 Regression Tree rmse        3651.\n10 LASSO           rmse        3819.\n\n\nWe see that the random forest model has the lowest MAE and RMSE, indicating that this model performs best on the test set!!!"
  },
  {
    "objectID": "Homework9.html#final-fits-and-summaries",
    "href": "Homework9.html#final-fits-and-summaries",
    "title": "Homework 9",
    "section": "Final Fits and Summaries",
    "text": "Final Fits and Summaries\nIn this section we extract the final model fits on the training data for each type and report a summary of each model.\nFor MLR and LASSO, we report final coefficient tables.\n\nrentals_fit_final |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 29 × 5\n   term                   estimate std.error statistic  p.value\n   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)              16273.     1722.     9.45  3.74e-18\n 2 rainfall_daily_poly_1   -29082.     6758.    -4.30  2.47e- 5\n 3 rainfall_daily_poly_2    10579.     3452.     3.06  2.44e- 3\n 4 snowfall_daily_poly_1     -805.     3517.    -0.229 8.19e- 1\n 5 snowfall_daily_poly_2    -2563.     3323.    -0.771 4.41e- 1\n 6 temp_mean_poly_1         27585.    76262.     0.362 7.18e- 1\n 7 temp_mean_poly_2        -10511.    19704.    -0.533 5.94e- 1\n 8 humidity_mean_poly_1    -27287.    27164.    -1.00  3.16e- 1\n 9 humidity_mean_poly_2     -6417.     6698.    -0.958 3.39e- 1\n10 wind_speed_mean_poly_1   -9615.     3445.    -2.79  5.68e- 3\n# ℹ 19 more rows\n\nLASSO_fit_final |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 3\n   term                 estimate      penalty\n   &lt;chr&gt;                   &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)           19869.  0.0000000001\n 2 rainfall_daily        -2117.  0.0000000001\n 3 snowfall_daily          -99.8 0.0000000001\n 4 temp_mean                 0   0.0000000001\n 5 humidity_mean         -1395.  0.0000000001\n 6 wind_speed_mean        -737.  0.0000000001\n 7 visibility_mean         -30.1 0.0000000001\n 8 dew_point_temp_mean    4450.  0.0000000001\n 9 solar_radiation_mean   3696.  0.0000000001\n10 holiday_No.Holiday     2652.  0.0000000001\n11 seasons_Spring        -5136.  0.0000000001\n12 seasons_Summer        -3743.  0.0000000001\n13 seasons_Winter        -8528.  0.0000000001\n14 weekend_Yes           -1791.  0.0000000001\n\n\nFor the regression tree model, we give a plot of the final fit.\n\ntree_fit_final |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\nFor the bagged tree and random forest models, we produce variable importance plots.\n\nbagg_plot_object &lt;- extract_fit_engine(bagg_fit_final)\nbagg_plot_object$imp |&gt; \n  mutate(term = factor(term, levels = term)) |&gt;  \n  ggplot(aes(x = term, y = value)) + geom_bar(stat =\"identity\") +  coord_flip()\n\n\n\n\n\n\n\n\nWe see that for the bagged tree model, average daily temp is the most important variable, followed by average dew point temp, and average solar radiation."
  }
]